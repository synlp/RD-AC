CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 torchrun --nnodes 1 --nproc_per_node 7 --master-port 21443 train.py \
    --model_name_or_path /media/ubuntu/data/share/Qwen2-VL-2B-Instruct \
    --training_data_path /media/ubuntu/data/yuanhe/project/affective_computing/processed_data/twitter2015/all_data.json \
    --training_image_dir /media/ubuntu/data/yuanhe/project/affective_computing/data/IJCAI2019_data/twitter2015_images \
    --training_lmr_dir /media/ubuntu/data/yuanhe/project/affective_computing/processed_data/twitter2015/train_emb \
    --data_name twitter \
    --output_dir ../output_model/qwen-twitter2015-base-cls \
    --save_total_limit 3 \
    --report_to none \
    --per_device_train_batch_size 1 \
    --gradient_accumulation_steps 1 \
    --learning_rate 1.0e-5 \
    --num_train_epochs 3 \
    --deepspeed examples/deepspeed/ds_z0_config.json \
    --bf16 true \
    --resume_from_checkpoint False \
    --save_strategy epoch \
    --eval_strategy epoch \
    --logging_steps 50

CUDA_VISIBLE_DEVICES=1,2,3,4,5,6,7 torchrun --nnodes 1 --nproc_per_node 7 --master-port 21443 train.py \
    --model_name_or_path /media/ubuntu/data/share/Qwen2-VL-2B-Instruct \
    --training_data_path /media/ubuntu/data/yuanhe/project/affective_computing/processed_data/twitter2015/all_data.json \
    --training_image_dir /media/ubuntu/data/yuanhe/project/affective_computing/data/IJCAI2019_data/twitter2015_images \
    --training_lmr_dir /media/ubuntu/data/yuanhe/project/affective_computing/processed_data/twitter2015/train_emb \
    --data_name twitter \
    --output_dir ../output_model/qwen-twitter2015-lmr-attention-cls \
    --save_total_limit 8 \
    --report_to none \
    --per_device_train_batch_size 1 \
    --gradient_accumulation_steps 1 \
    --learning_rate 1.0e-5 \
    --num_train_epochs 8 \
    --deepspeed examples/deepspeed/ds_z0_config.json \
    --bf16 true \
    --resume_from_checkpoint False \
    --save_strategy epoch \
    --eval_strategy epoch \
    --logging_steps 50 \
    --use_lmr \
    --use_attention
